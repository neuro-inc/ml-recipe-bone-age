kind: live
title: ml-recipe-bone-age
id: ml_recipe_bone_age

defaults:
  preset: cpu-small
  life_span: 1d

volumes:
  data:
    remote: storage:ml_recipe_bone_age/data
    mount: /ml-recipe-bone-age/data
    local: data
  remote_dataset:
    remote: storage:ml_recipe_bone_age/dataset
    mount: /ml-recipe-bone-age/dataset
  dvc_cache:
    remote: storage:ml_recipe_bone_age/dvc_cache
    mount: /ml-recipe-bone-age/dvc_cache
  postgress_storage:
    #remote: disk://neuro-compute/yevheniisemendiak/disk-9299764c-fcd5-42b0-adcb-4313f62ce6be
    remote: disk://neuro-compute/artemyushkovskiy/disk-24919d47-9a1c-40c0-9f75-f1464e23038a
    mount: /var/lib/postgresql/data
  mlflow_artifacts:
    remote: storage:ml_recipe_bone_age/mlruns
    mount: /usr/local/share/mlruns

images:
  train:
    ref: image:$[[ flow.project_id ]]:v1
    dockerfile: $[[ flow.workspace ]]/docker/train.dockerfile
    context: $[[ flow.workspace ]]/
    build_preset: gpu-k80-small-p
  cpu_worker:
    ref: image:$[[ flow.project_id ]]/cpu_worker:v1
    dockerfile: $[[ flow.workspace ]]/docker/cpu-worker.dockerfile
    context: $[[ flow.workspace ]]/
  seldon:
    ref: image:$[[ flow.project_id ]]/seldon:21.1.23
    dockerfile: $[[ flow.workspace ]]/seldon_deployment/seldon.Dockerfile
    context: $[[ flow.workspace ]]/
  label_studio:
    ref: image:$[[ flow.project_id ]]/label_studio:21.1.28
    dockerfile: $[[ flow.workspace ]]/label_studio/label_studio.Dockerfile
    context: $[[ flow.workspace ]]/label_studio

jobs:

  prepare_remote_dataset:
    image: neuromation/neuro-extras:20.12.15
    preset: cpu-small
    detach: False
    volumes:
      - ${{ volumes.remote_dataset.ref_rw }}
    params:
      dataset_url:
        default: http://data.neu.ro/bone-age-tiny.zip
        descr: URL of dataset to download
      force:
        default: ''
        descr: |
          If set to any valie and dataset directory already exists,
          delete existing directory and re-download dataset.
    bash: |
      set -o xtrace

      DATASET_URL=${{ params.dataset_url }}
      DST=$(basename ${DATASET_URL} .zip)
      DATASET_BASE_PATH=${{ volumes.remote_dataset.mount }}
      DATASET_PATH=${DATASET_BASE_PATH}/${DST}

      FORCE=${{ params.force }}

      if [ -d "${DATASET_PATH}" ] && [ "${FORCE}" ]; then
        echo "Dataset target directory already exist and force=true, deleting: '${DATASET_PATH}'"
        rm -r ${DATASET_PATH}
      fi

      if [ ! -d "${DATASET_PATH}" ]; then
        echo "Downloading dataset ${DATASET_URL} -> ${DATASET_PATH}"
        neuro-extras data cp --extract --use-temp-dir ${DATASET_URL} ${DATASET_PATH}

        echo "Cleaning up dataset {DATASET_PATH}"
        cd ${DATASET_PATH}
        mv data/test/*.png data/train
        rmdir data/test
        sed -n '1d;p' data/test.csv >> data/train.csv
        rm data/test.csv
        mv data/train/ images/
        mv data/train.csv annotations.csv
        rmdir data
      else
        echo "Dataset ${DATASET_PATH} already exists, skipping."
      fi

  prepare_git:
    image: ${{ images.cpu_worker.ref }}
    preset: cpu-small
    detach: False
    volumes:
      - secret:gh-rsa:/root/.ssh/id-rsa
    params:
      # BRANCH=$(git branch --show-current)
      # EXPERIMENT_BRANCH=${BRANCH}-experiment
      git_branch:
        # ... --param git_branch ${BRANCH}
        descr: "Git reference where to CHECKOUT the code and data from"
      create_git_branch:
        #  --param create_git_branch ${EXPERIMENT_BRANCH}
        descr: |
          Git reference where to COMMIT the new data to.
          By default equals to git_branch-experiment.
    env:
      PROJECT: /project
    workdir: /project
    bash: |
      set -o xtrace
      cd ${PROJECT}

      BRANCH=${{ params.git_branch }}
      CREATE_BRANCH=${{ params.create_git_branch }}
      CREATE_BRANCH=${CREATE_BRANCH:-$BRANCH-experiment}  # defaults to ${EXPERIMENT_BRANCH}
      test "${BRANCH}"
      test "${CREATE_BRANCH}"
      DVC_CACHE=${{ volumes.dvc_cache.mount }}

      URL=https://raw.githubusercontent.com/neuro-inc/ml-recipe-bone-age/${BRANCH}

      # RUN GIT EXPLICITLY
      bash <(curl -s ${URL}/scripts/git_checkout.sh) \
        git_branch="${BRANCH}" \
        create_git_branch="${CREATE_BRANCH}"
      
      bash <(curl -s ${URL}/scripts/git_commit.sh) \
        git_branch=${CREATE_BRANCH} \
        git_commit_msg="Create empty branch ${CREATE_BRANCH}"

  extend_data:
    image: ${{ images.cpu_worker.ref }}
    preset: cpu-small
    detach: False
    volumes:
      - ${{ volumes.remote_dataset.ref_rw }}
      - ${{ volumes.dvc_cache.ref_rw }}
      - secret:gh-rsa:/root/.ssh/id-rsa
    params:
      extend_dataset_by:
        default: "50"
        descr: "How many new images to add into current dataset"
      git_branch:
        # ... --param git_branch ${EXPERIMENT_BRANCH}
        descr: "Git reference where to CHECKOUT the code and data from"
    env:
      PROJECT: /project
    workdir: /project
    bash: |
      set -o xtrace
      cd ${PROJECT}

      BRANCH=${{ params.git_branch }}
      test "${BRANCH}"
      DVC_CACHE=${{ volumes.dvc_cache.mount }}

      URL=https://raw.githubusercontent.com/neuro-inc/ml-recipe-bone-age/${BRANCH}
      bash <(curl -s ${URL}/scripts/git_checkout.sh) git_branch="${BRANCH}"
      bash <(curl -s ${URL}/scripts/dvc_checkout.sh) dvc_cache_path="${DVC_CACHE}"

      echo "Extending dataset"
      python data_utils/extend_dataset.py \
        --cur_dataset data \
        --full_dataset ${{ volumes.remote_dataset.mount }}/bone-age-tiny \
        --nmber_of_imgs ${{ params.extend_dataset_by }}

      PATHS="data/annotations.csv, data/images"
      bash <(curl -s ${URL}/scripts/dvc_commit.sh) paths="${PATHS}"
      bash <(curl -s ${URL}/scripts/git_commit.sh) paths="${PATHS}" \
        git_branch=${BRANCH} \
        git_commit_msg="Auto-commit: update dataset: add ${{ params.extend_dataset_by }} images"

  label_studio:
    image: $[[ images.label_studio.ref ]]
    name: $[[ flow.title ]]-label-studio
    http_port: 443
    http_auth: True
    life_span: 1d
    detach: False
    browse: True
    volumes:
      - ${{ volumes.dvc_cache.ref_rw }}
      - ${{ volumes.remote_dataset.ref_rw }}
      - secret:gh-rsa:/root/.ssh/id-rsa
    params:
      extend_dataset_by: "1"
      git_branch:
        # BRANCH=$(git branch --show-current)
        # ... --param git_branch ${EXPERIMENT_BRANCH}
        descr: "Git reference where to CHECKOUT the code and data from"
    env:
      PROJECT: /project
    workdir: /project
    bash: |
      set -o xtrace
      cd ${PROJECT}

      BRANCH=${{ params.git_branch }}
      DVC_CACHE=${{ volumes.dvc_cache.mount }}

      URL=https://raw.githubusercontent.com/neuro-inc/ml-recipe-bone-age/${BRANCH}
      bash <(curl -s ${URL}/scripts/git_checkout.sh) git_branch="${BRANCH}"
      bash <(curl -s ${URL}/scripts/dvc_checkout.sh) dvc_cache_path="${DVC_CACHE}"

      echo "Extending dataset"
      python ${PROJECT}/data_utils/extend_dataset.py \
        --cur_dataset tmp_data \
        --full_dataset ${{ volumes.remote_dataset.mount }}/bone-age-tiny \
        --nmber_of_imgs ${{ params.extend_dataset_by }} \
        --skip_annotation_update

      echo "Starting label-studio"
      python ${PROJECT}/label_studio/launch_ls.py \
        --project_root ${PROJECT} \
        --ls_project_root ${PROJECT}/label-studio-project -- \
        start --use-gevent --no-browser \
          --label-config ./project/label_studio/LabelConfig.xml \
          --input-path ./project/tmp_data/images \
          --input-format image-dir \
          --host ${NEURO_JOB_NAME}--${NEURO_JOB_OWNER}.jobs.${NEURO_JOB_CLUSTER}.org.neu.ro \
          --port 443 \
          --allow-serving-local-files \
          --init \
          label-studio-project
      mv tmp_data/images/* data/images

      PATHS="data/annotations.csv, data/"
      bash <(curl -s ${URL}/scripts/dvc_commit.sh) paths="${PATHS}"
      bash <(curl -s ${URL}/scripts/git_commit.sh) paths="${PATHS}" \
        git_user_name="bot-${NEURO_JOB_OWNER}" \
        git_user_email="${NEURO_JOB_ID}.${NEURO_JOB_CLUSTER}@neu.ro" \
        git_commit_msg="Auto-commit: annotate dataset: annotate $(ls ../label-studio-project/completions | grep -v ^d | wc -l) images"

  postgres:
    image: postgres:12.5
    name: $[[ flow.title ]]-postgres
    http_port: 5432
    http_auth: False
    life_span: 30d
    detach: True
    volumes:
      - ${{ volumes.postgress_storage.remote }}:/var/lib/postgresql/data:rw
    env:
      POSTGRES_PASSWORD: password
      POSTGRES_INITDB_ARGS: ""
      PGDATA: /var/lib/postgresql/data/pgdata

  mlflow_server:
    image: neuromation/mlflow:1.11.0
    name: $[[ flow.title ]]-mlflow-server
    http_port: 5000
    http_auth: True
    life_span: 30d
    detach: True
    volumes:
      - ${{ volumes.mlflow_artifacts.ref_rw }}
    cmd: |
      server --host 0.0.0.0
        --backend-store-uri=postgresql://postgres:password@${{ inspect_job('postgres').name }}--${{ inspect_job('postgres').owner }}.platform-jobs:5432
        --default-artifact-root=${{ volumes.mlflow_artifacts.mount }}

  train:
    image: $[[ images.train.ref ]]
    preset: gpu-k80-small-p
    detach: False
    life_span: 10d
    volumes:
      - $[[ volumes.dvc_cache.ref_ro ]]
      - $[[ volumes.mlflow_artifacts.ref_rw ]]
      - secret:gh-rsa:/root/.ssh/id-rsa
    env:
      EXPOSE_SSH: "yes"
      MLFLOW_TRACKING_URI: "http://${{ inspect_job('mlflow_server').name }}--${{ inspect_job('mlflow_server').owner }}.platform-jobs:5000"
      PROJECT: /project
      PYTHONPATH: /project
    workdir: /project
    params:
      git_branch:
        # ... --param git_branch ${EXPERIMENT_BRANCH}
        descr: "Git reference where to CHECKOUT the code and data from"
    bash: |
      set -o xtrace
      cd ${PROJECT}

      BRANCH=${{ params.git_branch }}
      DVC_CACHE=${{ volumes.dvc_cache.mount }}

      URL=https://raw.githubusercontent.com/neuro-inc/ml-recipe-bone-age/${BRANCH}
      bash <(curl -s ${URL}/scripts/git_checkout.sh) git_branch="${BRANCH}"
      bash <(curl -s ${URL}/scripts/dvc_checkout.sh) dvc_cache_path="${DVC_CACHE}"

      sleep infinity
      echo "Training on $(ls data/images | wc -l) images"
      python -u src/train.py \
        --data_dir=data/images \
        --annotation_csv=data/annotations.csv \
        --n_epoch=5 \
      || sleep infinity

  deploy_inference_platform: # todo: Alexey is working on it
    image: $[[ images.seldon.ref ]]
    name: $[[ flow.title ]]-test-inference
    preset: gpu-k80-small-p
    http_port: 5000
    http_auth: False
    life_span: 5h
    detach: True
    env:
      PYTHONPATH: /microservice/src
    params:
      run_id:
    volumes:
      - ${{ volumes.mlflow_artifacts.remote }}/0/${{ params.run_id }}/artifacts/model/data/:/storage/

  locust: # todo: after inference
    image: locustio/locust:1.4.1
    name: $[[ flow.title ]]-locust
    http_port: 8080
    http_auth: False
    life_span: 1d
    detach: True
    browse: True
    params:
      endpoint_url:
    volumes:
      - $[[ upload(volumes.src).ref_ro ]]
      - $[[ upload(volumes.config).ref_ro ]]
      - $[[ volumes.remote_dataset.ref_ro ]]
    env:
      DOG_IDS: "n02085936, n02088094"
      IMGS_DIR: $[[ volumes.remote_dataset.mount ]]/images/Images/
      PYTHONPATH: $[[ volumes.src.mount ]]/..
    cmd: |
      # TODO (yartem): Note, we don't have src volume anymore! take code from git.;
      -f $[[ volumes.src.mount ]]/locust.py --web-port 8080 -H $[[ params.endpoint_url ]]

  filebrowser:
    action: gh:neuro-actions/filebrowser@master
    args:
      volumes_project_remote: $[[ volumes.project.remote ]]

  webdav_dvc:
    action: gh:neuro-actions/webdav_server@master
    args:
      volume_remote: $[[ volumes.dvc_cache.remote ]]
      job_name: $[[ flow.title ]]-webdav-dvc
      http_auth: ""

  webdav_mlflow:
    action: gh:neuro-actions/webdav_server@master
    args:
      volume_remote: $[[ volumes.mlflow_artifacts.remote ]]
      job_name: $[[ flow.title ]]-webdav-mlflow
      http_auth: ""
